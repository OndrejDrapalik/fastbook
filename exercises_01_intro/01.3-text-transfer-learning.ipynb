{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text transfer learning\n",
    "\n",
    "How to How to fine-tune a language model and train a classifier\n",
    "\n",
    "In this tutorial, we will see how we can train a model to classify text (here based on their sentiment). First we will see how to do this quickly in a few lines of code, then how to get state-of-the art results using the approach of the ULMFit paper.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text.all import *\n",
    "\n",
    "# Download the data and uncompressed it\n",
    "path = untar_data(URLs.IMDB)\n",
    "path.ls()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(path/'train').ls()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">The data follows an ImageNet-style organization, in the train folder, we have two subfolders, pos and neg (for positive reviews and negative reviews). We can gather it by using the TextDataLoaders.from_folder method. The only thing we need to specify is the name of the validation folder, which is “test” (and not the default “valid”)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = TextDataLoaders.from_folder(untar_data(URLs.IMDB), valid='test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls.show_batch()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">- xxbos to indicate the beginning of a text\n",
    ">- xxmaj to indicate the next word was capitalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Learner suitable for text classification in one line:\n",
    "\n",
    "learn = text_classifier_learner(dls, AWD_LSTM, drop_mult=0.5, metrics=accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">We use the AWD LSTM architecture, drop_mult is a parameter that controls the magnitude of all dropouts in that model, and we use accuracy to track down how well we are doing. We can then fine-tune our pretrained model:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    ">The first argument, 4, might be the number of epochs to fine-tune the model for. An epoch is a complete pass through the training data. So if the value of 4 is being used as the number of epochs, the model will be trained on the training data four times.\n",
    "\n",
    ">The second argument, 1e-2, might be the learning rate to use during fine-tuning. The learning rate is a hyperparameter that determines how fast the model will learn. It controls the step size at which the optimizer makes updates to the model parameters. A lower learning rate means that the model will learn more slowly, but it might also lead to more stable and accurate results. A higher learning rate means that the model will learn more quickly, but it might also lead to less stable and accurate results. The value of 1e-2 is a very small learning rate, so the model will likely learn slowly during fine-tuning.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fine_tune(4, 1e-2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a1f88d4cdea7c7502e2130d2eb4782fd7efa0a4ade7b7da31f967d36304c54a1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
